{
  "id": "strike-langchain-client-basic-py",
  "name": "langchain client basic py",
  "version": "0.1.0",
  "stack": [
    "langchain",
    "py"
  ],
  "tags": [
    "client",
    "basic",
    "generated",
    "strike"
  ],
  "description": "Auto-generated spike for langchain client in py (basic).",
  "params": [
    {
      "name": "app_name",
      "default": "langchain-client-app"
    }
  ],
  "files": [
    {
      "path": "src/langchain-client.py",
      "template": "# Spike: langchain client (py)\n# Auto-generated spike stub for langchain (client)\ndef demo():\n    print('use langchain - client (basic)')\n"
    },
    {
      "path": "src/langchain/basic.ts",
      "template": "import { ChatOpenAI } from '@langchain/openai';\nimport { ChatPromptTemplate } from '@langchain/core/prompts';\nexport async function run(prompt: string){\n  const llm = new ChatOpenAI({ model: 'gpt-4o-mini', apiKey: process.env.OPENAI_API_KEY });\n  const tpl = ChatPromptTemplate.fromMessages([['system','You are helpful.'],['human','{input}']]);\n  const chain = tpl.pipe(llm);\n  const res = await chain.invoke({ input: prompt });\n  return res?.content?.toString?.() || String(res);\n}\n"
    },
    {
      "path": "spikes/strike-langchain-client-basic-py.py.txt",
      "template": "# Spike: langchain client (py)\n# Auto-generated spike stub for langchain (client)\ndef demo():\n    print('use langchain - client (basic)')\n"
    },
    {
      "path": "spikes/strike-langchain-client-basic-py.md",
      "template": "# langchain client (basic, py)\n\nThis is an auto-generated spike template.\n"
    }
  ],
  "patches": []
}