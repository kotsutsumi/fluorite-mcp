{
  "id": "strike-tobi-prosody-annotator",
  "name": "ToBI Prosodic Annotation System",
  "stack": [
    "typescript",
    "linguistics",
    "prosody",
    "audio"
  ],
  "tags": [
    "tobi",
    "prosody",
    "intonation",
    "linguistics",
    "speech",
    "annotation",
    "rhythm"
  ],
  "description": "ToBI (Tones and Break Indices) prosodic annotation system for intonation pattern analysis and rhythm annotation",
  "files": [
    {
      "path": "src/prosody/tobi-annotator.ts",
      "template": "/**\n * ToBI (Tones and Break Indices) Prosodic Annotation System\n * Implements prosodic annotation for intonation and rhythm analysis\n */\n\nexport interface ToBITone {\n  type: 'H*' | 'L*' | 'H+L*' | 'L+H*' | 'H*+L' | 'L*+H' | 'H-' | 'L-' | 'H%' | 'L%' | '!H*' | '!L*';\n  position: number; // temporal position in ms\n  strength: number; // tonal strength (0-1)\n  description: string;\n}\n\nexport interface BreakIndex {\n  level: 0 | 1 | 2 | 3 | 4; // Break index levels\n  position: number; // temporal position in ms\n  type: 'word' | 'phrase' | 'clause' | 'utterance';\n  description: string;\n}\n\nexport interface ProsodyFeatures {\n  pitch: number[];      // F0 contour\n  intensity: number[];  // amplitude envelope\n  duration: number[];   // segment durations\n  timestamps: number[]; // temporal alignment\n}\n\nexport interface ToBIAnnotation {\n  tones: ToBITone[];\n  breaks: BreakIndex[];\n  words: string[];\n  syllables: string[];\n  phonemes: string[];\n  features: ProsodyFeatures;\n  metadata: {\n    speaker?: string;\n    language: string;\n    dialect?: string;\n    speaking_rate: 'slow' | 'normal' | 'fast';\n    emotion?: string;\n    confidence: number;\n  };\n}\n\nexport class ToBIAnnotator {\n  private readonly toneDescriptions = new Map<string, string>([\n    ['H*', 'high pitch accent'],\n    ['L*', 'low pitch accent'],\n    ['H+L*', 'falling pitch accent (high leading tone)'],\n    ['L+H*', 'rising pitch accent (low leading tone)'],\n    ['H*+L', 'high pitch accent with low trailing tone'],\n    ['L*+H', 'low pitch accent with high trailing tone'],\n    ['H-', 'high phrase accent'],\n    ['L-', 'low phrase accent'],\n    ['H%', 'high boundary tone'],\n    ['L%', 'low boundary tone'],\n    ['!H*', 'downstepped high pitch accent'],\n    ['!L*', 'upstepped low pitch accent']\n  ]);\n\n  private readonly breakDescriptions = new Map<number, string>([\n    [0, 'clitic boundary (no break)'],\n    [1, 'weak word boundary'],\n    [2, 'strong word boundary'],\n    [3, 'intermediate phrase boundary'],\n    [4, 'intonational phrase boundary']\n  ]);\n\n  /**\n   * Annotate text with ToBI prosodic features\n   */\n  annotate(text: string, features: ProsodyFeatures, options?: {\n    language?: string;\n    dialect?: string;\n    auto_detect_breaks?: boolean;\n    auto_detect_tones?: boolean;\n  }): ToBIAnnotation {\n    const words = this.tokenizeWords(text);\n    const syllables = this.syllabify(words);\n    const phonemes = this.phonemize(syllables);\n    \n    const tones = options?.auto_detect_tones ? \n      this.detectTones(features.pitch, features.timestamps) : [];\n    \n    const breaks = options?.auto_detect_breaks ? \n      this.detectBreaks(words, features.intensity, features.timestamps) : [];\n\n    return {\n      tones,\n      breaks,\n      words,\n      syllables,\n      phonemes,\n      features,\n      metadata: {\n        language: options?.language || 'en-US',\n        dialect: options?.dialect,\n        speaking_rate: this.detectSpeakingRate(features.duration),\n        confidence: this.calculateConfidence(tones, breaks)\n      }\n    };\n  }\n\n  /**\n   * Detect tonal targets from pitch contour\n   */\n  private detectTones(pitch: number[], timestamps: number[]): ToBITone[] {\n    const tones: ToBITone[] = [];\n    const smoothedPitch = this.smoothPitch(pitch);\n    const peaks = this.findPeaks(smoothedPitch);\n    const valleys = this.findValleys(smoothedPitch);\n    \n    // Detect pitch accents\n    for (const peak of peaks) {\n      const position = timestamps[peak] || peak * 10; // default 10ms intervals\n      const strength = this.calculateToneStrength(smoothedPitch, peak);\n      \n      tones.push({\n        type: 'H*',\n        position,\n        strength,\n        description: this.toneDescriptions.get('H*') || ''\n      });\n    }\n    \n    for (const valley of valleys) {\n      const position = timestamps[valley] || valley * 10;\n      const strength = this.calculateToneStrength(smoothedPitch, valley);\n      \n      tones.push({\n        type: 'L*',\n        position,\n        strength,\n        description: this.toneDescriptions.get('L*') || ''\n      });\n    }\n    \n    // Add boundary tones\n    if (pitch.length > 0) {\n      const finalPitch = pitch[pitch.length - 1];\n      const initialPitch = pitch[0];\n      const meanPitch = pitch.reduce((a, b) => a + b) / pitch.length;\n      \n      // Final boundary tone\n      tones.push({\n        type: finalPitch > meanPitch ? 'H%' : 'L%',\n        position: timestamps[timestamps.length - 1] || (pitch.length - 1) * 10,\n        strength: Math.abs(finalPitch - meanPitch) / meanPitch,\n        description: this.toneDescriptions.get(finalPitch > meanPitch ? 'H%' : 'L%') || ''\n      });\n    }\n    \n    return tones.sort((a, b) => a.position - b.position);\n  }\n\n  /**\n   * Detect prosodic breaks from intensity and word boundaries\n   */\n  private detectBreaks(words: string[], intensity: number[], timestamps: number[]): BreakIndex[] {\n    const breaks: BreakIndex[] = [];\n    const wordBoundaries = this.findWordBoundaries(words, timestamps);\n    \n    for (let i = 0; i < wordBoundaries.length - 1; i++) {\n      const boundary = wordBoundaries[i];\n      const nextBoundary = wordBoundaries[i + 1];\n      \n      // Calculate pause duration and intensity drop\n      const pauseDuration = nextBoundary - boundary;\n      const intensityDrop = this.calculateIntensityDrop(intensity, boundary, nextBoundary);\n      \n      // Determine break index level\n      let level: 0 | 1 | 2 | 3 | 4;\n      let type: 'word' | 'phrase' | 'clause' | 'utterance';\n      \n      if (pauseDuration > 500 && intensityDrop > 0.7) {\n        level = 4;\n        type = 'utterance';\n      } else if (pauseDuration > 300 && intensityDrop > 0.5) {\n        level = 3;\n        type = 'phrase';\n      } else if (pauseDuration > 150 && intensityDrop > 0.3) {\n        level = 2;\n        type = 'word';\n      } else if (pauseDuration > 50) {\n        level = 1;\n        type = 'word';\n      } else {\n        level = 0;\n        type = 'word';\n      }\n      \n      breaks.push({\n        level,\n        position: boundary,\n        type,\n        description: this.breakDescriptions.get(level) || ''\n      });\n    }\n    \n    return breaks;\n  }\n\n  /**\n   * Generate ToBI annotation string\n   */\n  generateToBIString(annotation: ToBIAnnotation): string {\n    const lines: string[] = [];\n    \n    // Words tier\n    lines.push('words\\t' + annotation.words.join(' '));\n    \n    // Break indices tier\n    const breakString = annotation.breaks\n      .map(b => `${b.level}@${b.position}`)\n      .join(' ');\n    lines.push('break\\t' + breakString);\n    \n    // Tones tier\n    const toneString = annotation.tones\n      .map(t => `${t.type}@${t.position}`)\n      .join(' ');\n    lines.push('tones\\t' + toneString);\n    \n    // Metadata\n    lines.push(`meta\\tlang=${annotation.metadata.language} rate=${annotation.metadata.speaking_rate} conf=${annotation.metadata.confidence.toFixed(2)}`);\n    \n    return lines.join('\\n');\n  }\n\n  /**\n   * Parse ToBI annotation string\n   */\n  parseToBIString(tobiString: string): Partial<ToBIAnnotation> {\n    const lines = tobiString.split('\\n');\n    const result: Partial<ToBIAnnotation> = {\n      tones: [],\n      breaks: [],\n      words: []\n    };\n    \n    for (const line of lines) {\n      const [tier, content] = line.split('\\t');\n      \n      switch (tier) {\n        case 'words':\n          result.words = content.split(' ');\n          break;\n          \n        case 'break':\n          result.breaks = content.split(' ').map(item => {\n            const [level, position] = item.split('@');\n            return {\n              level: parseInt(level) as 0 | 1 | 2 | 3 | 4,\n              position: parseInt(position),\n              type: 'word' as const,\n              description: this.breakDescriptions.get(parseInt(level)) || ''\n            };\n          });\n          break;\n          \n        case 'tones':\n          result.tones = content.split(' ').map(item => {\n            const [type, position] = item.split('@');\n            return {\n              type: type as ToBITone['type'],\n              position: parseInt(position),\n              strength: 1.0,\n              description: this.toneDescriptions.get(type) || ''\n            };\n          });\n          break;\n      }\n    }\n    \n    return result;\n  }\n\n  // Helper methods\n  private tokenizeWords(text: string): string[] {\n    return text.toLowerCase().replace(/[^\\w\\s]/g, '').split(/\\s+/).filter(w => w.length > 0);\n  }\n\n  private syllabify(words: string[]): string[] {\n    // Simple syllabification - in practice, use proper syllable detection\n    return words.flatMap(word => {\n      // Basic CV pattern detection\n      const syllables = word.match(/[bcdfghjklmnpqrstvwxyz]*[aeiou][bcdfghjklmnpqrstvwxyz]*/gi) || [word];\n      return syllables;\n    });\n  }\n\n  private phonemize(syllables: string[]): string[] {\n    // Convert to basic phonemic representation\n    // In practice, use proper phonemization library\n    return syllables.map(syl => {\n      // Basic English phoneme mapping\n      return syl.replace(/th/g, 'θ')\n                .replace(/sh/g, 'ʃ')\n                .replace(/ch/g, 'tʃ')\n                .replace(/ng/g, 'ŋ');\n    });\n  }\n\n  private smoothPitch(pitch: number[]): number[] {\n    // Simple moving average smoothing\n    const windowSize = 5;\n    const smoothed: number[] = [];\n    \n    for (let i = 0; i < pitch.length; i++) {\n      const start = Math.max(0, i - Math.floor(windowSize / 2));\n      const end = Math.min(pitch.length, i + Math.ceil(windowSize / 2));\n      const window = pitch.slice(start, end);\n      const average = window.reduce((a, b) => a + b) / window.length;\n      smoothed.push(average);\n    }\n    \n    return smoothed;\n  }\n\n  private findPeaks(signal: number[]): number[] {\n    const peaks: number[] = [];\n    for (let i = 1; i < signal.length - 1; i++) {\n      if (signal[i] > signal[i - 1] && signal[i] > signal[i + 1]) {\n        peaks.push(i);\n      }\n    }\n    return peaks;\n  }\n\n  private findValleys(signal: number[]): number[] {\n    const valleys: number[] = [];\n    for (let i = 1; i < signal.length - 1; i++) {\n      if (signal[i] < signal[i - 1] && signal[i] < signal[i + 1]) {\n        valleys.push(i);\n      }\n    }\n    return valleys;\n  }\n\n  private calculateToneStrength(pitch: number[], position: number): number {\n    const localMean = this.calculateLocalMean(pitch, position, 10);\n    const globalMean = pitch.reduce((a, b) => a + b) / pitch.length;\n    return Math.abs(pitch[position] - localMean) / globalMean;\n  }\n\n  private calculateLocalMean(signal: number[], center: number, window: number): number {\n    const start = Math.max(0, center - window);\n    const end = Math.min(signal.length, center + window);\n    const slice = signal.slice(start, end);\n    return slice.reduce((a, b) => a + b) / slice.length;\n  }\n\n  private findWordBoundaries(words: string[], timestamps: number[]): number[] {\n    // Estimate word boundaries based on word count and timestamps\n    const boundaries: number[] = [];\n    const totalDuration = timestamps[timestamps.length - 1] - timestamps[0];\n    const avgWordDuration = totalDuration / words.length;\n    \n    for (let i = 0; i < words.length; i++) {\n      boundaries.push(timestamps[0] + i * avgWordDuration);\n    }\n    \n    return boundaries;\n  }\n\n  private calculateIntensityDrop(intensity: number[], start: number, end: number): number {\n    const startIdx = Math.floor(start / 10); // assume 10ms intervals\n    const endIdx = Math.floor(end / 10);\n    \n    if (startIdx >= intensity.length || endIdx >= intensity.length) return 0;\n    \n    const startIntensity = intensity[startIdx];\n    const endIntensity = intensity[endIdx];\n    \n    return Math.abs(startIntensity - endIntensity) / Math.max(startIntensity, endIntensity);\n  }\n\n  private detectSpeakingRate(durations: number[]): 'slow' | 'normal' | 'fast' {\n    const avgDuration = durations.reduce((a, b) => a + b) / durations.length;\n    \n    if (avgDuration > 150) return 'slow';\n    if (avgDuration < 80) return 'fast';\n    return 'normal';\n  }\n\n  private calculateConfidence(tones: ToBITone[], breaks: BreakIndex[]): number {\n    // Simple confidence measure based on annotation density\n    const toneConfidence = Math.min(1.0, tones.length / 10);\n    const breakConfidence = Math.min(1.0, breaks.length / 5);\n    return (toneConfidence + breakConfidence) / 2;\n  }\n}\n\n// Export singleton instance\nexport const tobiAnnotator = new ToBIAnnotator();\n"
    },
    {
      "path": "src/prosody/prosody-analyzer.ts",
      "template": "/**\n * Prosodic analysis utilities for speech processing\n */\n\nimport { ToBIAnnotation, ProsodyFeatures } from './tobi-annotator';\n\nexport interface RhythmPattern {\n  beats: number[];           // beat positions in ms\n  tempo: number;             // beats per minute\n  stress_pattern: number[];  // stress levels (0-3)\n  regularity: number;        // rhythm regularity (0-1)\n}\n\nexport interface IntonationContour {\n  f0_mean: number;\n  f0_range: number;\n  f0_slope: number;\n  declination: number;\n  reset_points: number[];\n}\n\nexport interface ProsodyAnalysis {\n  rhythm: RhythmPattern;\n  intonation: IntonationContour;\n  phrasing: {\n    phrase_count: number;\n    phrase_lengths: number[];\n    pause_durations: number[];\n  };\n  speaking_style: {\n    rate: 'slow' | 'normal' | 'fast';\n    volume: 'quiet' | 'normal' | 'loud';\n    pitch_range: 'narrow' | 'normal' | 'wide';\n    emotion: string;\n  };\n}\n\nexport class ProsodyAnalyzer {\n  /**\n   * Analyze prosodic features from ToBI annotation\n   */\n  analyze(annotation: ToBIAnnotation): ProsodyAnalysis {\n    const rhythm = this.analyzeRhythm(annotation);\n    const intonation = this.analyzeIntonation(annotation.features.pitch, annotation.features.timestamps);\n    const phrasing = this.analyzePhrasing(annotation.breaks);\n    const speaking_style = this.analyzeSpeakingStyle(annotation);\n    \n    return {\n      rhythm,\n      intonation,\n      phrasing,\n      speaking_style\n    };\n  }\n\n  /**\n   * Extract rhythmic patterns\n   */\n  private analyzeRhythm(annotation: ToBIAnnotation): RhythmPattern {\n    const stressedSyllables = this.findStressedSyllables(annotation.tones);\n    const beats = this.extractBeats(stressedSyllables);\n    const tempo = this.calculateTempo(beats);\n    const stress_pattern = this.extractStressPattern(annotation.tones);\n    const regularity = this.calculateRhythmRegularity(beats);\n    \n    return {\n      beats,\n      tempo,\n      stress_pattern,\n      regularity\n    };\n  }\n\n  /**\n   * Analyze intonation contour\n   */\n  private analyzeIntonation(pitch: number[], timestamps: number[]): IntonationContour {\n    const validPitch = pitch.filter(p => p > 0 && !isNaN(p));\n    \n    const f0_mean = validPitch.reduce((a, b) => a + b) / validPitch.length;\n    const f0_range = Math.max(...validPitch) - Math.min(...validPitch);\n    const f0_slope = this.calculateSlope(validPitch, timestamps);\n    const declination = this.calculateDeclination(validPitch);\n    const reset_points = this.findResetPoints(validPitch);\n    \n    return {\n      f0_mean,\n      f0_range,\n      f0_slope,\n      declination,\n      reset_points\n    };\n  }\n\n  /**\n   * Analyze phrasing structure\n   */\n  private analyzePhrasing(breaks: any[]) {\n    const phraseBoundaries = breaks.filter(b => b.level >= 3);\n    const phrase_count = phraseBoundaries.length + 1;\n    \n    const phrase_lengths: number[] = [];\n    const pause_durations: number[] = [];\n    \n    for (let i = 0; i < phraseBoundaries.length; i++) {\n      const start = i === 0 ? 0 : phraseBoundaries[i - 1].position;\n      const end = phraseBoundaries[i].position;\n      phrase_lengths.push(end - start);\n      \n      // Estimate pause duration based on break level\n      const pauseDuration = phraseBoundaries[i].level * 100; // ms\n      pause_durations.push(pauseDuration);\n    }\n    \n    return {\n      phrase_count,\n      phrase_lengths,\n      pause_durations\n    };\n  }\n\n  /**\n   * Analyze speaking style\n   */\n  private analyzeSpeakingStyle(annotation: ToBIAnnotation) {\n    const rate = annotation.metadata.speaking_rate;\n    const volume = this.categorizeVolume(annotation.features.intensity);\n    const pitch_range = this.categorizePitchRange(annotation.features.pitch);\n    const emotion = this.detectEmotion(annotation);\n    \n    return {\n      rate,\n      volume,\n      pitch_range,\n      emotion\n    };\n  }\n\n  // Helper methods\n  private findStressedSyllables(tones: any[]): number[] {\n    return tones\n      .filter(tone => tone.type.includes('*')) // pitch accents\n      .map(tone => tone.position);\n  }\n\n  private extractBeats(stressedPositions: number[]): number[] {\n    // Use stressed syllables as beat markers\n    return stressedPositions.sort((a, b) => a - b);\n  }\n\n  private calculateTempo(beats: number[]): number {\n    if (beats.length < 2) return 0;\n    \n    const intervals = [];\n    for (let i = 1; i < beats.length; i++) {\n      intervals.push(beats[i] - beats[i - 1]);\n    }\n    \n    const avgInterval = intervals.reduce((a, b) => a + b) / intervals.length;\n    return 60000 / avgInterval; // BPM\n  }\n\n  private extractStressPattern(tones: any[]): number[] {\n    return tones.map(tone => {\n      if (tone.type === 'H*') return 3; // primary stress\n      if (tone.type === 'L*') return 2; // secondary stress\n      if (tone.type.includes('*')) return 1; // weak stress\n      return 0; // unstressed\n    });\n  }\n\n  private calculateRhythmRegularity(beats: number[]): number {\n    if (beats.length < 3) return 0;\n    \n    const intervals = [];\n    for (let i = 1; i < beats.length; i++) {\n      intervals.push(beats[i] - beats[i - 1]);\n    }\n    \n    const mean = intervals.reduce((a, b) => a + b) / intervals.length;\n    const variance = intervals.reduce((acc, val) => acc + Math.pow(val - mean, 2), 0) / intervals.length;\n    const cv = Math.sqrt(variance) / mean; // coefficient of variation\n    \n    return Math.max(0, 1 - cv); // higher = more regular\n  }\n\n  private calculateSlope(pitch: number[], timestamps: number[]): number {\n    if (pitch.length < 2) return 0;\n    \n    const n = pitch.length;\n    const sumX = timestamps.reduce((a, b) => a + b);\n    const sumY = pitch.reduce((a, b) => a + b);\n    const sumXY = timestamps.reduce((acc, x, i) => acc + x * pitch[i], 0);\n    const sumXX = timestamps.reduce((acc, x) => acc + x * x, 0);\n    \n    const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);\n    return slope;\n  }\n\n  private calculateDeclination(pitch: number[]): number {\n    // Calculate overall downward trend\n    const firstHalf = pitch.slice(0, Math.floor(pitch.length / 2));\n    const secondHalf = pitch.slice(Math.floor(pitch.length / 2));\n    \n    const firstMean = firstHalf.reduce((a, b) => a + b) / firstHalf.length;\n    const secondMean = secondHalf.reduce((a, b) => a + b) / secondHalf.length;\n    \n    return (firstMean - secondMean) / firstMean;\n  }\n\n  private findResetPoints(pitch: number[]): number[] {\n    const resetPoints: number[] = [];\n    const threshold = 50; // Hz\n    \n    for (let i = 1; i < pitch.length - 1; i++) {\n      const jump = pitch[i + 1] - pitch[i];\n      if (Math.abs(jump) > threshold) {\n        resetPoints.push(i);\n      }\n    }\n    \n    return resetPoints;\n  }\n\n  private categorizeVolume(intensity: number[]): 'quiet' | 'normal' | 'loud' {\n    const avgIntensity = intensity.reduce((a, b) => a + b) / intensity.length;\n    \n    if (avgIntensity < 0.3) return 'quiet';\n    if (avgIntensity > 0.7) return 'loud';\n    return 'normal';\n  }\n\n  private categorizePitchRange(pitch: number[]): 'narrow' | 'normal' | 'wide' {\n    const validPitch = pitch.filter(p => p > 0 && !isNaN(p));\n    if (validPitch.length === 0) return 'normal';\n    \n    const range = Math.max(...validPitch) - Math.min(...validPitch);\n    const mean = validPitch.reduce((a, b) => a + b) / validPitch.length;\n    const relativeRange = range / mean;\n    \n    if (relativeRange < 0.3) return 'narrow';\n    if (relativeRange > 0.8) return 'wide';\n    return 'normal';\n  }\n\n  private detectEmotion(annotation: ToBIAnnotation): string {\n    // Simple emotion detection based on prosodic features\n    const avgPitch = annotation.features.pitch.reduce((a, b) => a + b) / annotation.features.pitch.length;\n    const pitchVariance = this.calculateVariance(annotation.features.pitch);\n    const speakingRate = annotation.metadata.speaking_rate;\n    \n    if (avgPitch > 200 && pitchVariance > 1000 && speakingRate === 'fast') {\n      return 'excited';\n    } else if (avgPitch < 150 && pitchVariance < 500 && speakingRate === 'slow') {\n      return 'sad';\n    } else if (pitchVariance > 1500) {\n      return 'surprised';\n    } else {\n      return 'neutral';\n    }\n  }\n\n  private calculateVariance(values: number[]): number {\n    const mean = values.reduce((a, b) => a + b) / values.length;\n    return values.reduce((acc, val) => acc + Math.pow(val - mean, 2), 0) / values.length;\n  }\n}\n\n// Export singleton instance\nexport const prosodyAnalyzer = new ProsodyAnalyzer();\n"
    },
    {
      "path": "test/prosody.test.ts",
      "template": "/**\n * Test suite for prosodic processing\n */\n\nimport { describe, it, expect } from 'vitest';\nimport { tobiAnnotator, ToBIAnnotation } from '../src/prosody/tobi-annotator';\nimport { prosodyAnalyzer } from '../src/prosody/prosody-analyzer';\n\ndescribe('ToBI Annotator', () => {\n  it('should create basic ToBI annotation', () => {\n    const mockFeatures = {\n      pitch: [150, 180, 200, 170, 140],\n      intensity: [0.8, 0.9, 0.7, 0.6, 0.5],\n      duration: [100, 120, 110, 130, 140],\n      timestamps: [0, 100, 220, 330, 460]\n    };\n    \n    const annotation = tobiAnnotator.annotate('Hello world', mockFeatures, {\n      language: 'en-US',\n      auto_detect_tones: true,\n      auto_detect_breaks: true\n    });\n    \n    expect(annotation.words).toEqual(['hello', 'world']);\n    expect(annotation.tones.length).toBeGreaterThan(0);\n    expect(annotation.breaks.length).toBeGreaterThan(0);\n    expect(annotation.metadata.language).toBe('en-US');\n  });\n\n  it('should generate ToBI string representation', () => {\n    const mockAnnotation: ToBIAnnotation = {\n      words: ['hello', 'world'],\n      tones: [{\n        type: 'H*',\n        position: 100,\n        strength: 0.8,\n        description: 'high pitch accent'\n      }],\n      breaks: [{\n        level: 1,\n        position: 250,\n        type: 'word',\n        description: 'weak word boundary'\n      }],\n      syllables: ['hel', 'lo', 'world'],\n      phonemes: ['h', 'ɛ', 'l', 'o', 'w', 'ə', 'r', 'l', 'd'],\n      features: {\n        pitch: [150, 180, 140],\n        intensity: [0.8, 0.9, 0.7],\n        duration: [100, 120, 110],\n        timestamps: [0, 100, 220]\n      },\n      metadata: {\n        language: 'en-US',\n        speaking_rate: 'normal',\n        confidence: 0.8\n      }\n    };\n    \n    const tobiString = tobiAnnotator.generateToBIString(mockAnnotation);\n    expect(tobiString).toContain('words\\thello world');\n    expect(tobiString).toContain('H*@100');\n    expect(tobiString).toContain('1@250');\n  });\n\n  it('should parse ToBI string', () => {\n    const tobiString = `words\\thello world\nbreak\\t1@250\ntones\\tH*@100`;\n    const parsed = tobiAnnotator.parseToBIString(tobiString);\n    \n    expect(parsed.words).toEqual(['hello', 'world']);\n    expect(parsed.tones?.[0].type).toBe('H*');\n    expect(parsed.tones?.[0].position).toBe(100);\n    expect(parsed.breaks?.[0].level).toBe(1);\n    expect(parsed.breaks?.[0].position).toBe(250);\n  });\n});\n\ndescribe('Prosody Analyzer', () => {\n  it('should analyze prosodic features', () => {\n    const mockAnnotation: ToBIAnnotation = {\n      words: ['hello', 'beautiful', 'world'],\n      tones: [\n        { type: 'H*', position: 100, strength: 0.8, description: 'high pitch accent' },\n        { type: 'L*', position: 300, strength: 0.6, description: 'low pitch accent' },\n        { type: 'H%', position: 500, strength: 0.7, description: 'high boundary tone' }\n      ],\n      breaks: [\n        { level: 1, position: 200, type: 'word', description: 'weak word boundary' },\n        { level: 3, position: 400, type: 'phrase', description: 'intermediate phrase boundary' }\n      ],\n      syllables: ['hel', 'lo', 'beau', 'ti', 'ful', 'world'],\n      phonemes: ['h', 'ɛ', 'l', 'o', 'b', 'j', 'u', 't', 'ɪ', 'f', 'ə', 'l', 'w', 'ə', 'r', 'l', 'd'],\n      features: {\n        pitch: [150, 180, 200, 170, 140, 160, 130],\n        intensity: [0.8, 0.9, 0.85, 0.7, 0.6, 0.75, 0.5],\n        duration: [100, 120, 110, 130, 140, 120, 150],\n        timestamps: [0, 100, 220, 330, 460, 600, 720]\n      },\n      metadata: {\n        language: 'en-US',\n        speaking_rate: 'normal',\n        confidence: 0.85\n      }\n    };\n    \n    const analysis = prosodyAnalyzer.analyze(mockAnnotation);\n    \n    expect(analysis.rhythm).toBeDefined();\n    expect(analysis.rhythm.beats.length).toBeGreaterThan(0);\n    expect(analysis.rhythm.tempo).toBeGreaterThan(0);\n    \n    expect(analysis.intonation).toBeDefined();\n    expect(analysis.intonation.f0_mean).toBeGreaterThan(0);\n    expect(analysis.intonation.f0_range).toBeGreaterThan(0);\n    \n    expect(analysis.phrasing).toBeDefined();\n    expect(analysis.phrasing.phrase_count).toBeGreaterThan(0);\n    \n    expect(analysis.speaking_style).toBeDefined();\n    expect(analysis.speaking_style.rate).toBe('normal');\n  });\n\n  it('should detect speaking styles', () => {\n    const fastSpeechAnnotation: ToBIAnnotation = {\n      words: ['quick', 'speech'],\n      tones: [],\n      breaks: [],\n      syllables: ['quick', 'speech'],\n      phonemes: ['k', 'w', 'ɪ', 'k', 's', 'p', 'i', 'tʃ'],\n      features: {\n        pitch: [200, 220, 240, 210],\n        intensity: [0.9, 0.95, 0.85, 0.8],\n        duration: [50, 60, 55, 65], // short durations = fast speech\n        timestamps: [0, 50, 110, 165]\n      },\n      metadata: {\n        language: 'en-US',\n        speaking_rate: 'fast',\n        confidence: 0.9\n      }\n    };\n    \n    const analysis = prosodyAnalyzer.analyze(fastSpeechAnnotation);\n    expect(analysis.speaking_style.rate).toBe('fast');\n    expect(analysis.speaking_style.volume).toBe('loud');\n    expect(analysis.speaking_style.pitch_range).toBe('normal');\n  });\n});\n"
    },
    {
      "path": "package.json",
      "template": "{\n  \"name\": \"tobi-prosody-annotator\",\n  \"version\": \"1.0.0\",\n  \"description\": \"ToBI (Tones and Break Indices) prosodic annotation system\",\n  \"type\": \"module\",\n  \"main\": \"dist/index.js\",\n  \"types\": \"dist/index.d.ts\",\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"test\": \"vitest\",\n    \"dev\": \"tsc --watch\",\n    \"lint\": \"eslint src/**/*.ts\"\n  },\n  \"dependencies\": {\n    \"audio-buffer\": \"^5.0.0\",\n    \"fft-js\": \"^0.0.12\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.0.0\",\n    \"typescript\": \"^5.0.0\",\n    \"vitest\": \"^1.0.0\",\n    \"eslint\": \"^8.0.0\",\n    \"@typescript-eslint/eslint-plugin\": \"^6.0.0\",\n    \"@typescript-eslint/parser\": \"^6.0.0\"\n  },\n  \"keywords\": [\n    \"tobi\",\n    \"prosody\",\n    \"intonation\",\n    \"linguistics\",\n    \"speech\",\n    \"annotation\",\n    \"rhythm\",\n    \"pitch\",\n    \"tones\",\n    \"breaks\"\n  ]\n}\n"
    },
    {
      "path": "README.md",
      "template": "# ToBI Prosodic Annotation System\\n\\nA comprehensive TypeScript implementation of the ToBI (Tones and Break Indices) system for prosodic annotation of speech intonation and rhythm.\\n\\n## Features\\n\\n- **ToBI Annotation**: Complete implementation of the ToBI prosodic annotation standard\\n- **Automatic Detection**: AI-powered detection of tones and break indices from audio features\\n- **Prosodic Analysis**: Comprehensive analysis of rhythm, intonation, and phrasing\\n- **Speaking Style Detection**: Automatic classification of speaking rate, volume, and emotion\\n- **Multi-format Support**: Import/export ToBI annotations in standard formats\\n- **TypeScript**: Full type safety and IntelliSense support\\n\\n## Installation\\n\\n```bash\\nnpm install tobi-prosody-annotator\\n```\\n\\n## Usage\\n\\n### Basic ToBI Annotation\\n\\n```typescript\\nimport { tobiAnnotator } from 'tobi-prosody-annotator';\\n\\nconst prosodyFeatures = {\\n  pitch: [150, 180, 200, 170, 140],        // F0 contour in Hz\\n  intensity: [0.8, 0.9, 0.7, 0.6, 0.5],   // amplitude envelope\\n  duration: [100, 120, 110, 130, 140],     // segment durations in ms\\n  timestamps: [0, 100, 220, 330, 460]     // temporal alignment\\n};\\n\\nconst annotation = tobiAnnotator.annotate('Hello world', prosodyFeatures, {\\n  language: 'en-US',\\n  auto_detect_tones: true,\\n  auto_detect_breaks: true\\n});\\n\\nconsole.log(annotation.tones);  // Detected pitch accents and boundary tones\\nconsole.log(annotation.breaks); // Break indices (0-4)\\n```\\n\\n### Prosodic Analysis\\n\\n```typescript\\nimport { prosodyAnalyzer } from 'tobi-prosody-annotator';\\n\\nconst analysis = prosodyAnalyzer.analyze(annotation);\\n\\nconsole.log(analysis.rhythm.tempo);           // BPM\\nconsole.log(analysis.intonation.f0_range);    // Pitch range\\nconsole.log(analysis.speaking_style.rate);    // 'slow' | 'normal' | 'fast'\\nconsole.log(analysis.speaking_style.emotion); // Detected emotion\\n```\\n\\n### ToBI String Format\\n\\n```typescript\\n// Generate ToBI annotation string\\nconst tobiString = tobiAnnotator.generateToBIString(annotation);\\nconsole.log(tobiString);\\n// Output:\\n// words\\tHello world\\n// break\\t1@250 3@500\\n// tones\\tH*@100 L%@500\\n\\n// Parse ToBI string\\nconst parsed = tobiAnnotator.parseToBIString(tobiString);\\n```\\n\\n## ToBI Reference\\n\\n### Tone Types\\n\\n| Symbol | Description |\\n|--------|-------------|\\n| H* | High pitch accent |\\n| L* | Low pitch accent |\\n| H+L* | Falling pitch accent (high leading tone) |\\n| L+H* | Rising pitch accent (low leading tone) |\\n| H*+L | High pitch accent with low trailing tone |\\n| L*+H | Low pitch accent with high trailing tone |\\n| H- | High phrase accent |\\n| L- | Low phrase accent |\\n| H% | High boundary tone |\\n| L% | Low boundary tone |\\n| !H* | Downstepped high pitch accent |\\n| !L* | Upstepped low pitch accent |\\n\\n### Break Indices\\n\\n| Level | Description |\\n|-------|-------------|\\n| 0 | Clitic boundary (no break) |\\n| 1 | Weak word boundary |\\n| 2 | Strong word boundary |\\n| 3 | Intermediate phrase boundary |\\n| 4 | Intonational phrase boundary |\\n\\n## API Reference\\n\\n### ToBIAnnotator\\n\\n- annotate(text: string, features: ProsodyFeatures, options?: AnnotationOptions): ToBIAnnotation\\n- generateToBIString(annotation: ToBIAnnotation): string\\n- parseToBIString(tobiString: string): Partial<ToBIAnnotation>\\n\\n### ProsodyAnalyzer\\n\\n- analyze(annotation: ToBIAnnotation): ProsodyAnalysis\\n\\n### Data Types\\n\\n```typescript\\ninterface ToBITone {\\n  type: 'H*' | 'L*' | 'H+L*' | 'L+H*' | 'H*+L' | 'L*+H' | 'H-' | 'L-' | 'H%' | 'L%' | '!H*' | '!L*';\\n  position: number;    // temporal position in ms\\n  strength: number;    // tonal strength (0-1)\\n  description: string;\\n}\\n\\ninterface BreakIndex {\\n  level: 0 | 1 | 2 | 3 | 4;\\n  position: number;    // temporal position in ms\\n  type: 'word' | 'phrase' | 'clause' | 'utterance';\\n  description: string;\\n}\\n```\\n\\n## Examples\\n\\n### Emotion Detection\\n\\n```typescript\\nconst emotionalSpeech = {\\n  pitch: [220, 260, 240, 200, 180],    // high, variable pitch\\n  intensity: [0.9, 0.95, 0.8, 0.7, 0.6],\\n  duration: [80, 90, 85, 95, 100],     // fast speech\\n  timestamps: [0, 80, 170, 255, 350]\\n};\\n\\nconst annotation = tobiAnnotator.annotate('I am so excited!', emotionalSpeech, {\\n  auto_detect_tones: true\\n});\\n\\nconst analysis = prosodyAnalyzer.analyze(annotation);\\nconsole.log(analysis.speaking_style.emotion); // 'excited'\\n```\\n\\n### Rhythm Analysis\\n\\n```typescript\\nconst rhythmicSpeech = {\\n  pitch: [150, 170, 160, 175, 165, 180, 155],\\n  intensity: [0.8, 0.9, 0.7, 0.85, 0.75, 0.9, 0.8],\\n  duration: [120, 110, 115, 108, 125, 105, 130], // regular timing\\n  timestamps: [0, 120, 230, 345, 453, 578, 683]\\n};\\n\\nconst annotation = tobiAnnotator.annotate('This has a steady rhythm', rhythmicSpeech);\\nconst analysis = prosodyAnalyzer.analyze(annotation);\\n\\nconsole.log(analysis.rhythm.tempo);      // BPM\\nconsole.log(analysis.rhythm.regularity); // 0-1 scale\\n```\\n\\n## Contributing\\n\\nContributions welcome! Please ensure tests pass and follow ToBI annotation standards.\\n\\n```bash\\nnpm test\\nnpm run lint\\n```\\n\\n## References\\n\\n- Beckman, M. E., & Ayers, G. M. (1997). Guidelines for ToBI labelling\\n- Silverman, K. et al. (1992). ToBI: A standard for labeling English prosody\\n- Jun, S. A. (Ed.). (2005). Prosodic Typology: The Phonology of Intonation and Phrasing\\n\\n## License\\n\\nMIT License - see LICENSE file for details.\\n"\n    }\n  ],\n  \"patches\": []\n}"
    }
  ],
  "patches": []
}