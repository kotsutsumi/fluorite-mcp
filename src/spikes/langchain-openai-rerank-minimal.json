{
  "id": "langchain-openai-rerank-minimal",
  "name": "LangChain LLM Rerank with OpenAI Minimal (Node)",
  "version": "1.0.0",
  "stack": ["node", "langchain", "openai"],
  "tags": ["rag", "rerank"],
  "description": "Use a simple LLM scoring prompt to rerank retrieved docs.",
  "params": [{ "name": "app_name", "default": "lc-llm-rerank" }],
  "files": [
    { "path": "{{app_name}}/index.mjs", "template": "import { OpenAIEmbeddings, ChatOpenAI } from '@langchain/openai';\nimport { MemoryVectorStore } from 'langchain/vectorstores/memory';\nconst docs = [{ pageContent: 'fluorite mcp spike' }, { pageContent: 'hello world' }];\nconst embeddings = new OpenAIEmbeddings({ apiKey: process.env.OPENAI_API_KEY });\nconst store = await MemoryVectorStore.fromDocuments(docs, embeddings);\nconst query = 'fluorite';\nconst initial = await store.similaritySearch(query, 2);\nconst llm = new ChatOpenAI({ apiKey: process.env.OPENAI_API_KEY });\nconst scored = await Promise.all(initial.map(async d=>{ const out = await llm.invoke(`Score 0..1 relevance of: ${d.pageContent} for query: ${query}`); const m = String(out.content).match(/0?\.\d+|1(?:\.0+)?/); return { d, s: m? Number(m[0]): 0 }; }));\nscored.sort((a,b)=> b.s-a.s);\nconsole.log(scored.map(x=>({ text: x.d.pageContent, score: x.s })));\n" },
    { "path": "{{app_name}}/package.json", "template": "{ \"name\": \"{{app_name}}\", \"type\": \"module\", \"private\": true, \"dependencies\": { \"@langchain/openai\": \"latest\", \"langchain\": \"latest\" } }\n" },
    { "path": "{{app_name}}/.env.example", "template": "OPENAI_API_KEY=sk-...\n" } 
  ],
  "patches": []
}

